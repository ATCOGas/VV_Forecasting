{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset for Faults Analysis against Weather Data\n",
    "Munge datasets from multiple sources into a single dataframe for analysis\n",
    "<br>\n",
    "Step 1: [Setup file and folder paths](#setup)<br>\n",
    "Step 2: [Build dataframe from multiple files](#multiple)<br>\n",
    "  or  : [Load previously build dataframe](#single)<br>\n",
    "Step 3: [Clean dataframe](#clean)<br>\n",
    "Step 4: [Combine into single dataframe](#combine)<br>\n",
    "Step 5: [Write dataframe to file](#write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup file and folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working folder: C:\\Users\\tdavies\\Desktop\\Data_Science\\Projects\\VV_Forecasting\\notebooks\n",
      "Current data folder: C:\\Users\\tdavies\\Desktop\\Data_Science\\Projects\\VV_Forecasting\\data\n",
      "Current output folder: C:\\Users\\tdavies\\Desktop\\Data_Science\\Projects\\VV_Forecasting\\output\n",
      "BOM data folder: C:\\Users\\tdavies\\Desktop\\Data_Science\\Projects\\VV_Forecasting\\data\\BOM\n",
      "Files in data folder:['BOM', 'BOM Station Locations.xlsx', 'DS FLOC.xlsx', 'FLOC (minus DS).xlsx', 'Notifs 2009-2018.xlsx', 'WA_Postcodes.xlsx', 'Weather.xlsx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "data_folder = path.join(path.abspath('..'), 'data')\n",
    "bom_data_folder = path.join(path.abspath('..'), 'data\\BOM')\n",
    "output_folder = path.join(path.abspath('..'), 'output')\n",
    "\n",
    "print ('Current working folder: ' + current_folder)\n",
    "print ('Current data folder: ' + data_folder)\n",
    "print ('Current output folder: ' + output_folder)\n",
    "print ('BOM data folder: ' + bom_data_folder)\n",
    "print ('Files in data folder:' + str(os.listdir(data_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='single'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataframe from previously built xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded.\n"
     ]
    }
   ],
   "source": [
    "filename = 'corrective_maint_against_weather.csv'\n",
    "#filename = 'binary_weather.csv'\n",
    "df_complete = pd.read_csv(path.join(data_folder, filename))\n",
    "print ('File loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>notif_date</th>\n",
       "      <th>floc</th>\n",
       "      <th>order</th>\n",
       "      <th>job_type</th>\n",
       "      <th>object_part_code</th>\n",
       "      <th>object_part_text</th>\n",
       "      <th>damage_code</th>\n",
       "      <th>damage_code_text</th>\n",
       "      <th>cause_code</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_date</th>\n",
       "      <th>evapo_trans_0000_2400</th>\n",
       "      <th>rain_0900_0900</th>\n",
       "      <th>pan_evap_0900_0900</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_rel_humidity</th>\n",
       "      <th>min_rel_humidity</th>\n",
       "      <th>avg_10m_wind_speed</th>\n",
       "      <th>solar_radiation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>504107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>34.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>673096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.24</td>\n",
       "      <td>34.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>810841.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.63</td>\n",
       "      <td>34.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.2</td>\n",
       "      <td>17.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>34.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>117547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF1</td>\n",
       "      <td>PIPE</td>\n",
       "      <td>Pipe</td>\n",
       "      <td>BROK</td>\n",
       "      <td>Broken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>34.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  notif_date      floc  order job_type object_part_code  \\\n",
       "0           0  2011-12-21  504107.0    NaN      SPH              NaN   \n",
       "1           1  2011-12-21  673096.0    NaN      SPL              NaN   \n",
       "2           2  2011-12-21  810841.0    NaN      SPH              NaN   \n",
       "3           3  2011-12-21      27.0    NaN      SPH              NaN   \n",
       "4           4  2011-12-21  117547.0    NaN      SF1             PIPE   \n",
       "\n",
       "  object_part_text damage_code damage_code_text cause_code       ...        \\\n",
       "0              NaN         NaN              NaN        NaN       ...         \n",
       "1              NaN         NaN              NaN        NaN       ...         \n",
       "2              NaN         NaN              NaN        NaN       ...         \n",
       "3              NaN         NaN              NaN        NaN       ...         \n",
       "4             Pipe        BROK           Broken        NaN       ...         \n",
       "\n",
       "  weather_date evapo_trans_0000_2400 rain_0900_0900 pan_evap_0900_0900  \\\n",
       "0   2011-12-21                   7.3            0.0                NaN   \n",
       "1   2011-12-21                   7.9            0.0                NaN   \n",
       "2   2011-12-21                   NaN            NaN                NaN   \n",
       "3   2011-12-21                   7.2            0.0                NaN   \n",
       "4   2011-12-21                   7.3            0.0                NaN   \n",
       "\n",
       "  max_temp min_temp max_rel_humidity min_rel_humidity avg_10m_wind_speed  \\\n",
       "0     28.9     13.6             97.0             32.0               3.87   \n",
       "1     30.6     16.4             82.0             35.0               4.24   \n",
       "2     25.8      NaN             91.0             61.0               4.63   \n",
       "3     29.2     17.4             89.0             38.0               3.37   \n",
       "4     28.9     13.6             97.0             32.0               3.87   \n",
       "\n",
       "  solar_radiation  \n",
       "0           34.47  \n",
       "1           34.47  \n",
       "2           34.24  \n",
       "3           34.38  \n",
       "4           34.47  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multiple'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build single weather dataframe from multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import multiple CSV files from BOM into one dataframe\n",
    "# Takes about a minute to run...\n",
    "import glob\n",
    "\n",
    "all_stations = pd.DataFrame()\n",
    "\n",
    "folder_list = os.listdir(bom_data_folder)\n",
    "for folder in folder_list:\n",
    "    csv_list = glob.glob(path.join(path.abspath(bom_data_folder), folder+'\\*.csv'))\n",
    "    df = pd.concat([pd.read_csv(f, header=None, skiprows=13) for f in csv_list], ignore_index=True)\n",
    "    all_stations = all_stations.append(df , ignore_index=False)\n",
    "\n",
    "# Add dataframe column headings\n",
    "all_stations.columns=['station_name', 'weather_date', 'evapo_trans_0000_2400', 'rain_0900_0900', 'pan_evap_0900_0900',\n",
    "                          'max_temp','min_temp', 'max_rel_humidity','min_rel_humidity', 'avg_10m_wind_speed','solar_radiation']\n",
    "\n",
    "# Remove totals rows and reindex\n",
    "all_stations = all_stations[all_stations['station_name'] != 'Totals:']\n",
    "all_stations = all_stations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save concatenated files into a single file so above code does not need to continually be rerun\n",
    "# Takes about one minute to run\n",
    "\n",
    "output_filename = 'Weather.xlsx'\n",
    "sheet_name = 'Sheet1'\n",
    "output = pd.ExcelWriter(path.join(data_folder, output_filename), engine='xlsxwriter')\n",
    "all_stations.to_excel(output, sheet_name)\n",
    "output.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data into individual dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maintenance data loaded.\n",
      "Domestic service assets loaded.\n",
      "Other assets loaded.\n",
      "Post codes loaded.\n",
      "Weather stations loaded.\n",
      "Weather data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load data into individual dataframes\n",
    "# Takes about two minutes to load...\n",
    "\n",
    "df_notifs = pd.ExcelFile(path.join(data_folder, 'Notifs 2009-2018.xlsx')).parse('Sheet1')\n",
    "print ('Maintenance data loaded.')\n",
    "df_ds_floc_master_data = pd.ExcelFile(path.join(data_folder, 'DS FLOC.xlsx')).parse('DS FLOC')\n",
    "print ('Domestic service assets loaded.')\n",
    "df_else_floc_master_data = pd.ExcelFile(path.join(data_folder, 'FLOC (minus DS).xlsx')).parse('FL')\n",
    "print ('Other assets loaded.')\n",
    "df_postcodes = pd.ExcelFile(path.join(data_folder, 'WA_Postcodes.xlsx')).parse('postcodes')\n",
    "print ('Post codes loaded.')\n",
    "df_stations = pd.ExcelFile(path.join(data_folder, 'BOM Station Locations.xlsx')).parse('Stations')\n",
    "print ('Weather stations loaded.')\n",
    "df_weather = pd.ExcelFile(path.join(data_folder, 'Weather.xlsx')).parse('Sheet1')\n",
    "print ('Weather data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data has loaded as intended\n",
    "\n",
    "#df_notifs.head()\n",
    "#df_ds_floc_master_data.head()\n",
    "#df_else_floc_master_data.head()\n",
    "#df_postcodes.head()\n",
    "#df_stations.head()\n",
    "#df_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data loaded into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip out all columns that will not be explicitly used by this particular analysis. These 'cleaning' algorithms will need to be tweaked for different analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean df_notifs dataframe\n",
    "There are several code blocks below that build a dataframe for notifications analysis. Depending on the anlysis you want to do, select the appropriate code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_notifs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Failure Analysis Dataframe\n",
    "Use this code block to form dataframe for failure analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_notifs\n",
    "\n",
    "df.set_index('Notification')\n",
    "clean = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Fields that can be directly copied to clean dataframe\n",
    "make_copy = (\n",
    "    ('Notification', 'notif'),\n",
    "    ('Notif.date', 'notif_date')\n",
    "    \n",
    ")\n",
    "for orig, new in make_copy:\n",
    "    clean[new] = df[orig]\n",
    "\n",
    "# Numeric columns\n",
    "clean['notif'] = pd.to_numeric(df['Notification']*1., errors='coerce')# recast notification number from int64 to float64\n",
    "clean['floc'] = pd.to_numeric(df['Functional Loc.'], errors='coerce')\n",
    "clean['order'] = pd.to_numeric(df['Order'], errors='coerce')\n",
    "\n",
    "# Categorical columns\n",
    "# TODO: Maintain spreadsheet containing lists of all these codes and load them for application here\n",
    "make_categorical = (  # has column, new_name, category pairs\n",
    "    ('Job Type', 'job_type', None),\n",
    "    ('ObjectPartCode', 'object_part_code', None),\n",
    "    ('ObjPartCodeText', 'object_part_text', None),\n",
    "    ('Damage Code', 'damage_code', None),\n",
    "    ('Prob. code text', 'damage_code_text', None),\n",
    "    ('Cause code', 'cause_code', None),\n",
    "    ('Cause code text', 'cause_code_text', None),\n",
    "    ('Unit', 'duration_units', None),\n",
    "    ('Breakdown', 'breakdown', ('X','')),\n",
    "    ('Object Code group', 'object_code_group', None),\n",
    "    ('Obj.p. grp.txt.', 'object_group_text', None),\n",
    "    ('Notifictn type', 'notif_type', ('SP','SF')),\n",
    "    ('Cause Code group', 'cause_code_group', None),\n",
    "    ('Cause grp. text', 'cause_group_text', None)\n",
    ")\n",
    "\n",
    "for column, new_name, cats in make_categorical:\n",
    "    clean[new_name] = pd.Categorical(df[column], categories=cats)\n",
    "\n",
    "clean_notifs = clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Variable Volume Job Type Analysis Dataframe\n",
    "Use this code block to form dataframe for VV Forecasting analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_notifs\n",
    "\n",
    "df.set_index('Notification')\n",
    "clean = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Fields that can be directly copied to clean dataframe\n",
    "make_copy = (\n",
    "    ('Notification', 'notif'),\n",
    "    ('Notif.date', 'notif_date')\n",
    "    \n",
    ")\n",
    "for orig, new in make_copy:\n",
    "    clean[new] = df[orig]\n",
    "\n",
    "# Numeric columns\n",
    "clean['notif'] = pd.to_numeric(df['Notification']*1., errors='coerce')# recast notification number from int64 to float64\n",
    "clean['floc'] = pd.to_numeric(df['Functional Loc.'], errors='coerce')\n",
    "clean['order'] = pd.to_numeric(df['Order'], errors='coerce')\n",
    "\n",
    "# Categorical columns\n",
    "clean['job_type'] = pd.Categorical(df['Job Type'], categories=None)\n",
    "\n",
    "clean_notifs = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_notifs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean df_ds_floc_master_data dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe contains master data associated with all domestic gas distribution services in WA\n",
    "Primary key is TPLNR field,(functional location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ds_floc_master_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ds_floc_master_data\n",
    "\n",
    "df.set_index('TPLNR')\n",
    "clean = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Fields that can be directly copied to clean dataframe\n",
    "make_copy = (\n",
    "    ('MTRMD_I', 'meter_model'),\n",
    "    ('MTRDT_I', 'meter_install_date')\n",
    ")\n",
    "for orig, new in make_copy:\n",
    "    clean[new] = df[orig]\n",
    "\n",
    "# Numeric columns\n",
    "clean['floc'] = pd.to_numeric(df['TPLNR'], errors='coerce')\n",
    "clean['supply_pressure'] = pd.to_numeric(df['SUP_PRS'], errors='coerce')\n",
    "clean['postcode'] = pd.to_numeric(df['PCODE'], errors='coerce')\n",
    "\n",
    "# Categorical columns\n",
    "make_categorical = (  # has column, new_name, category pairs\n",
    "    ('RBNR', 'catalog_profile', None),\n",
    "    ('LOCN', 'network', ('NM','SM','MA','BU','BS','KA','AL','GE'))\n",
    ")\n",
    "\n",
    "for column, new_name, cats in make_categorical:\n",
    "    clean[new_name] = pd.Categorical(df[column], categories=cats)\n",
    "\n",
    "clean_ds_floc_master_data = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_ds_floc_master_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean df_else_floc_master_data dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe contains master data associated with all ATCO Gas assets other than domestic services loaded above\n",
    "Primary key:TPLNR    #functional location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_else_floc_master_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_else_floc_master_data\n",
    "\n",
    "df.set_index('Functional Loc.')\n",
    "clean = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Numeric columns\n",
    "clean['floc'] = pd.to_numeric(df['Functional Loc.'], errors='coerce')\n",
    "clean['postcode'] = pd.to_numeric(df['Postal Code'], errors='coerce')\n",
    "\n",
    "# Categorical columns\n",
    "make_categorical = (  # has column, new_name, category pairs\n",
    "    ('Catalog profile', 'catalog_profile', ('MAIN','GATESTN','REGSET','METERSET','VALVE','RECTFR','SERV_LINE','COMMETER')),\n",
    "    ('Location', 'network', ('NM','SM','MA','BU','BS','KA','AL','GE')),\n",
    "    ('City', 'suburb', None)\n",
    ")\n",
    "\n",
    "for column, new_name, cats in make_categorical:\n",
    "    clean[new_name] = pd.Categorical(df[column], categories=cats)\n",
    "\n",
    "clean_else_floc_master_data = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_else_floc_master_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean df_postcodes dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe contains WA postcodes and their associated lat/lon.\n",
    "Primary key: postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_postcodes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_postcodes\n",
    "\n",
    "df.set_index('postcode')\n",
    "clean = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Numeric columns\n",
    "clean['postcode'] = pd.to_numeric(df['postcode'], errors='coerce')\n",
    "clean['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
    "clean['lon'] = pd.to_numeric(df['long'], errors='coerce')\n",
    "\n",
    "# Categorical column\n",
    "clean['suburb'] = pd.Categorical(df['locality'], categories=None)\n",
    "\n",
    "#clean = clean.set_index('postcode')\n",
    "clean_postcodes = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_postcodes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean df_stations dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe contains a list of BOM weather stations in WA and their associated lat/lon.\n",
    "Primary key: STN ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_stations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_stations\n",
    "\n",
    "df.set_index('STN ID')\n",
    "clean = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Field that can be directly copied to clean dataframe\n",
    "clean['station_id'] = df['STN ID']\n",
    "\n",
    "# Numeric columns\n",
    "clean['lat'] = pd.to_numeric(df['LAT'], errors='coerce')\n",
    "clean['lon'] = pd.to_numeric(df['LON'], errors='coerce')\n",
    "\n",
    "# Categorical columns\n",
    "clean['station_name'] = pd.Categorical(df['NAME'], categories=None)\n",
    "\n",
    "clean = clean.set_index('station_id')\n",
    "clean_stations = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_stations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean df_weather dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe contains a list of features obtained from BOM weather stations in WA.\n",
    "Primary key: None. >> Link with Station name and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_weather\n",
    "\n",
    "clean = pd.DataFrame()\n",
    "\n",
    "# Datetime columns\n",
    "clean['weather_date'] = pd.to_datetime(df['weather_date'])\n",
    "\n",
    "# Numeric columns\n",
    "clean['evapo_trans_0000_2400'] = pd.to_numeric(df['evapo_trans_0000_2400'], errors='coerce')\n",
    "clean['rain_0900_0900'] = pd.to_numeric(df['rain_0900_0900'], errors='coerce')\n",
    "clean['pan_evap_0900_0900'] = pd.to_numeric(df['pan_evap_0900_0900'], errors='coerce')\n",
    "clean['max_temp'] = pd.to_numeric(df['max_temp'], errors='coerce')\n",
    "clean['min_temp'] = pd.to_numeric(df['min_temp'], errors='coerce')\n",
    "clean['max_rel_humidity'] = pd.to_numeric(df['max_rel_humidity'], errors='coerce')\n",
    "clean['min_rel_humidity'] = pd.to_numeric(df['min_rel_humidity'], errors='coerce')\n",
    "clean['avg_10m_wind_speed'] = pd.to_numeric(df['avg_10m_wind_speed'], errors='coerce')\n",
    "clean['solar_radiation'] = pd.to_numeric(df['solar_radiation'], errors='coerce')\n",
    "\n",
    "# Categorical columns\n",
    "clean['station_name'] = pd.Categorical(df['station_name'], categories=cats)\n",
    "\n",
    "clean = clean.set_index('station_name')\n",
    "clean_weather = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='combine'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine dataframes into a single dataframe to be used for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine asset master data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join DS functional locations and other asset functional locations into a single dataframe\n",
    "df = clean_ds_floc_master_data.append(clean_else_floc_master_data, sort=True)\n",
    "\n",
    "df_assets = df.drop_duplicates(subset=['floc'])\n",
    "df_assets = df_assets.set_index('floc')\n",
    "\n",
    "#df_assets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add asset data to maintenance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notif</th>\n",
       "      <th>notif_date</th>\n",
       "      <th>floc</th>\n",
       "      <th>order</th>\n",
       "      <th>job_type</th>\n",
       "      <th>catalog_profile</th>\n",
       "      <th>meter_install_date</th>\n",
       "      <th>meter_model</th>\n",
       "      <th>network</th>\n",
       "      <th>postcode</th>\n",
       "      <th>suburb</th>\n",
       "      <th>supply_pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300713965.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>504107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SM</td>\n",
       "      <td>6110.0</td>\n",
       "      <td>SOUTHERN RIVER</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300719006.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>673096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPL</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SM</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>KELMSCOTT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300719010.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>810841.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NM</td>\n",
       "      <td>6019.0</td>\n",
       "      <td>WEMBLEY DOWNS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300719430.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NM</td>\n",
       "      <td>6026.0</td>\n",
       "      <td>WOODVALE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300730505.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>117547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF1</td>\n",
       "      <td>DOMMETER</td>\n",
       "      <td>14.01.2014</td>\n",
       "      <td>M8A</td>\n",
       "      <td>SM</td>\n",
       "      <td>6153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         notif notif_date      floc  order job_type catalog_profile  \\\n",
       "0  300713965.0 2011-12-21  504107.0    NaN      SPH            MAIN   \n",
       "1  300719006.0 2011-12-21  673096.0    NaN      SPL            MAIN   \n",
       "2  300719010.0 2011-12-21  810841.0    NaN      SPH            MAIN   \n",
       "3  300719430.0 2011-12-21      27.0    NaN      SPH            MAIN   \n",
       "4  300730505.0 2011-12-21  117547.0    NaN      SF1        DOMMETER   \n",
       "\n",
       "  meter_install_date meter_model network  postcode          suburb  \\\n",
       "0                NaN         NaN      SM    6110.0  SOUTHERN RIVER   \n",
       "1                NaN         NaN      SM    6111.0       KELMSCOTT   \n",
       "2                NaN         NaN      NM    6019.0   WEMBLEY DOWNS   \n",
       "3                NaN         NaN      NM    6026.0        WOODVALE   \n",
       "4         14.01.2014         M8A      SM    6153.0             NaN   \n",
       "\n",
       "   supply_pressure  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4             1.25  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join combined asset master data above to maintenance dataframe\n",
    "df_maint = clean_notifs.merge(df_assets, left_on='floc', right_on='floc', how='left')\n",
    "\n",
    "#df_maint = df_maint.set_index('notif')\n",
    "\n",
    "df_maint.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Station dataframe with postcodes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances from each suburb centroid to idently closest weather station and then add station row to suburb dataframe\n",
    "# Takes about three minutes to run\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "result = pd.DataFrame()\n",
    "clean_postcodes_stn = pd.DataFrame()\n",
    "\n",
    "for postcode, pc_row in clean_postcodes.iterrows():\n",
    "    min_dist = 1000\n",
    "    for station_id, stn_row in clean_stations.iterrows():\n",
    "        # Use Pythagoras, not accurate but I don't know how to make it better...\n",
    "        dist = ((pc_row['lat']-stn_row['lat'])**2 + (pc_row['lon']-stn_row['lon'])**2)**0.5 \n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            p_code = pc_row['postcode']\n",
    "            stn_name = stn_row['station_name']\n",
    "        \n",
    "        result = pd.DataFrame({'postcode': [p_code],\n",
    "                               'station_name': [stn_name],\n",
    "                               'distance': [min_dist]})\n",
    "        \n",
    "    result = result.reset_index(drop=True) \n",
    "    clean_postcodes_stn = clean_postcodes_stn.append(result, ignore_index=True)\n",
    "\n",
    "clean_postcodes_stn.columns=['postcode', 'station_name', 'distance']   \n",
    "clean_postcodes_stn = clean_postcodes_stn.drop_duplicates(subset=['postcode'])\n",
    "\n",
    "#clean_postcodes_stn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add weather station name to maintenance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notif</th>\n",
       "      <th>notif_date</th>\n",
       "      <th>floc</th>\n",
       "      <th>order</th>\n",
       "      <th>job_type</th>\n",
       "      <th>catalog_profile</th>\n",
       "      <th>meter_install_date</th>\n",
       "      <th>meter_model</th>\n",
       "      <th>network</th>\n",
       "      <th>postcode</th>\n",
       "      <th>suburb</th>\n",
       "      <th>supply_pressure</th>\n",
       "      <th>station_name</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300713965.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>504107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SM</td>\n",
       "      <td>6110.0</td>\n",
       "      <td>SOUTHERN RIVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JANDAKOT AERO</td>\n",
       "      <td>0.131159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300719006.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>673096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPL</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SM</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>KELMSCOTT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BICKLEY</td>\n",
       "      <td>0.099496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300719010.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>810841.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NM</td>\n",
       "      <td>6019.0</td>\n",
       "      <td>WEMBLEY DOWNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SWANBOURNE</td>\n",
       "      <td>0.049014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300719430.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NM</td>\n",
       "      <td>6026.0</td>\n",
       "      <td>WOODVALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERTH METRO</td>\n",
       "      <td>0.138307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300730505.0</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>117547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF1</td>\n",
       "      <td>DOMMETER</td>\n",
       "      <td>14.01.2014</td>\n",
       "      <td>M8A</td>\n",
       "      <td>SM</td>\n",
       "      <td>6153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.25</td>\n",
       "      <td>JANDAKOT AERO</td>\n",
       "      <td>0.087419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         notif notif_date      floc  order job_type catalog_profile  \\\n",
       "0  300713965.0 2011-12-21  504107.0    NaN      SPH            MAIN   \n",
       "1  300719006.0 2011-12-21  673096.0    NaN      SPL            MAIN   \n",
       "2  300719010.0 2011-12-21  810841.0    NaN      SPH            MAIN   \n",
       "3  300719430.0 2011-12-21      27.0    NaN      SPH            MAIN   \n",
       "4  300730505.0 2011-12-21  117547.0    NaN      SF1        DOMMETER   \n",
       "\n",
       "  meter_install_date meter_model network  postcode          suburb  \\\n",
       "0                NaN         NaN      SM    6110.0  SOUTHERN RIVER   \n",
       "1                NaN         NaN      SM    6111.0       KELMSCOTT   \n",
       "2                NaN         NaN      NM    6019.0   WEMBLEY DOWNS   \n",
       "3                NaN         NaN      NM    6026.0        WOODVALE   \n",
       "4         14.01.2014         M8A      SM    6153.0             NaN   \n",
       "\n",
       "   supply_pressure   station_name  distance  \n",
       "0              NaN  JANDAKOT AERO  0.131159  \n",
       "1              NaN        BICKLEY  0.099496  \n",
       "2              NaN     SWANBOURNE  0.049014  \n",
       "3              NaN    PERTH METRO  0.138307  \n",
       "4             1.25  JANDAKOT AERO  0.087419  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add station name to maintenance data\n",
    "df_maint = df_maint.merge(clean_postcodes_stn, on='postcode', how='left')\n",
    "\n",
    "df_maint.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add weather data to maintenance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather to maintenance data\n",
    "# Use weather station name and date as keys\n",
    "df_complete = pd.merge(df_maint, clean_weather, left_on=['station_name','notif_date'], \n",
    "                       right_on=['station_name','weather_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notif_date</th>\n",
       "      <th>floc</th>\n",
       "      <th>order</th>\n",
       "      <th>job_type</th>\n",
       "      <th>catalog_profile</th>\n",
       "      <th>meter_install_date</th>\n",
       "      <th>meter_model</th>\n",
       "      <th>network</th>\n",
       "      <th>postcode</th>\n",
       "      <th>suburb</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_date</th>\n",
       "      <th>evapo_trans_0000_2400</th>\n",
       "      <th>rain_0900_0900</th>\n",
       "      <th>pan_evap_0900_0900</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_rel_humidity</th>\n",
       "      <th>min_rel_humidity</th>\n",
       "      <th>avg_10m_wind_speed</th>\n",
       "      <th>solar_radiation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notif</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300713965.0</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>504107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SM</td>\n",
       "      <td>6110.0</td>\n",
       "      <td>SOUTHERN RIVER</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>34.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300719006.0</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>673096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPL</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SM</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>KELMSCOTT</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.24</td>\n",
       "      <td>34.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300719010.0</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>810841.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NM</td>\n",
       "      <td>6019.0</td>\n",
       "      <td>WEMBLEY DOWNS</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.63</td>\n",
       "      <td>34.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300719430.0</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPH</td>\n",
       "      <td>MAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NM</td>\n",
       "      <td>6026.0</td>\n",
       "      <td>WOODVALE</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.2</td>\n",
       "      <td>17.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>34.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300730505.0</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>117547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF1</td>\n",
       "      <td>DOMMETER</td>\n",
       "      <td>14.01.2014</td>\n",
       "      <td>M8A</td>\n",
       "      <td>SM</td>\n",
       "      <td>6153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>34.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            notif_date      floc  order job_type catalog_profile  \\\n",
       "notif                                                              \n",
       "300713965.0 2011-12-21  504107.0    NaN      SPH            MAIN   \n",
       "300719006.0 2011-12-21  673096.0    NaN      SPL            MAIN   \n",
       "300719010.0 2011-12-21  810841.0    NaN      SPH            MAIN   \n",
       "300719430.0 2011-12-21      27.0    NaN      SPH            MAIN   \n",
       "300730505.0 2011-12-21  117547.0    NaN      SF1        DOMMETER   \n",
       "\n",
       "            meter_install_date meter_model network  postcode          suburb  \\\n",
       "notif                                                                          \n",
       "300713965.0                NaN         NaN      SM    6110.0  SOUTHERN RIVER   \n",
       "300719006.0                NaN         NaN      SM    6111.0       KELMSCOTT   \n",
       "300719010.0                NaN         NaN      NM    6019.0   WEMBLEY DOWNS   \n",
       "300719430.0                NaN         NaN      NM    6026.0        WOODVALE   \n",
       "300730505.0         14.01.2014         M8A      SM    6153.0             NaN   \n",
       "\n",
       "                  ...         weather_date evapo_trans_0000_2400  \\\n",
       "notif             ...                                              \n",
       "300713965.0       ...           2011-12-21                   7.3   \n",
       "300719006.0       ...           2011-12-21                   7.9   \n",
       "300719010.0       ...           2011-12-21                   NaN   \n",
       "300719430.0       ...           2011-12-21                   7.2   \n",
       "300730505.0       ...           2011-12-21                   7.3   \n",
       "\n",
       "             rain_0900_0900 pan_evap_0900_0900  max_temp  min_temp  \\\n",
       "notif                                                                \n",
       "300713965.0             0.0                NaN      28.9      13.6   \n",
       "300719006.0             0.0                NaN      30.6      16.4   \n",
       "300719010.0             NaN                NaN      25.8       NaN   \n",
       "300719430.0             0.0                NaN      29.2      17.4   \n",
       "300730505.0             0.0                NaN      28.9      13.6   \n",
       "\n",
       "             max_rel_humidity  min_rel_humidity  avg_10m_wind_speed  \\\n",
       "notif                                                                 \n",
       "300713965.0              97.0              32.0                3.87   \n",
       "300719006.0              82.0              35.0                4.24   \n",
       "300719010.0              91.0              61.0                4.63   \n",
       "300719430.0              89.0              38.0                3.37   \n",
       "300730505.0              97.0              32.0                3.87   \n",
       "\n",
       "             solar_radiation  \n",
       "notif                         \n",
       "300713965.0            34.47  \n",
       "300719006.0            34.47  \n",
       "300719010.0            34.24  \n",
       "300719430.0            34.38  \n",
       "300730505.0            34.47  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete = df_complete.set_index(df_complete.columns[0])\n",
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='write'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write cleaned and combined data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_file = path.join(data_folder, 'corrective_maint_against_weather.csv')\n",
    "csv_file = path.join(data_folder, 'corrective_maint_job_types.csv')\n",
    "df_complete.to_csv(csv_file)\n",
    "\n",
    "#csv_file = path.join(data_folder, 'binary_weather.csv')\n",
    "#df_wide.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert catagorical columns to binary to enable PCA dimensionality reduction later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = pd.DataFrame()\n",
    "\n",
    "# Fields to directly copy to new analysis dataframe\n",
    "make_copy = (\n",
    "    ('weather_date', 'date'),\n",
    "    #('evapo_trans_0000_2400', 'evapo_trans_0000_2400'),\n",
    "    #('rain_0900_0900', 'rain_0900_0900'),\n",
    "    #('pan_evap_0900_0900', 'pan_evap_0900_0900'),\n",
    "    ('max_temp', 'max_temp'),\n",
    "    ('min_temp', 'min_temp'),\n",
    "    #('max_rel_humidity', 'max_rel_humidity'),\n",
    "    #('min_rel_humidity', 'min_rel_humidity'),\n",
    "    #('avg_10m_wind_speed', 'avg_10m_wind_speed'),\n",
    "    #('solar_radiation', 'solar_radiation')\n",
    ")\n",
    "for orig, new in make_copy:\n",
    "    df_wide[new] = df_complete[orig]\n",
    "\n",
    "cat = pd.get_dummies(df_complete['catalog_profile'])\n",
    "job = pd.get_dummies(df_complete['job_type'])\n",
    "#net = pd.get_dummies(df_complete['network'])\n",
    "#obj = pd.get_dummies(df_complete['object_part_code'])\n",
    "#dam = pd.get_dummies(df_complete['damage_code'])\n",
    "#cau = pd.get_dummies(df_complete['cause_code'])\n",
    "\n",
    "\n",
    "df_wide = df_wide.join(cat)\n",
    "df_wide = df_wide.join(job)\n",
    "#df_wide = df_wide.join(net)\n",
    "#df_wide = df_wide.append(obj, sort=False)\n",
    "#df_wide = df_wide.append(dam, sort=False)\n",
    "#df_wide = df_wide.append(cau, sort=False)\n",
    "\n",
    "\n",
    "df_wide=df_wide.set_index('date')\n",
    "df_wide=df_wide.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>COMMETER</th>\n",
       "      <th>DOMMETER</th>\n",
       "      <th>GATESTN</th>\n",
       "      <th>MAIN</th>\n",
       "      <th>METERSET</th>\n",
       "      <th>RECTFR</th>\n",
       "      <th>REGSET</th>\n",
       "      <th>VALVE</th>\n",
       "      <th>...</th>\n",
       "      <th>SPN</th>\n",
       "      <th>SPO</th>\n",
       "      <th>SPP</th>\n",
       "      <th>SPR</th>\n",
       "      <th>SPT</th>\n",
       "      <th>SPU</th>\n",
       "      <th>SPW</th>\n",
       "      <th>SPX</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-21</th>\n",
       "      <td>28.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-21</th>\n",
       "      <td>30.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-21</th>\n",
       "      <td>25.8</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-21</th>\n",
       "      <td>29.2</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-21</th>\n",
       "      <td>28.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_temp  min_temp  COMMETER  DOMMETER  GATESTN  MAIN  METERSET  \\\n",
       "date                                                                          \n",
       "2011-12-21      28.9      13.6         0         0        0     1         0   \n",
       "2011-12-21      30.6      16.4         0         0        0     1         0   \n",
       "2011-12-21      25.8      16.9         0         0        0     1         0   \n",
       "2011-12-21      29.2      17.4         0         0        0     1         0   \n",
       "2011-12-21      28.9      13.6         0         1        0     0         0   \n",
       "\n",
       "            RECTFR  REGSET  VALVE ...   SPN  SPO  SPP  SPR  SPT  SPU  SPW  \\\n",
       "date                              ...                                       \n",
       "2011-12-21       0       0      0 ...     0    0    0    0    0    0    0   \n",
       "2011-12-21       0       0      0 ...     0    0    0    0    0    0    0   \n",
       "2011-12-21       0       0      0 ...     0    0    0    0    0    0    0   \n",
       "2011-12-21       0       0      0 ...     0    0    0    0    0    0    0   \n",
       "2011-12-21       0       0      0 ...     0    0    0    0    0    0    0   \n",
       "\n",
       "            SPX  SPY  SPZ  \n",
       "date                       \n",
       "2011-12-21    0    0    0  \n",
       "2011-12-21    0    0    0  \n",
       "2011-12-21    0    0    0  \n",
       "2011-12-21    0    0    0  \n",
       "2011-12-21    0    0    0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Analysis Frame to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = path.join(data_folder, 'binary_weather.csv')\n",
    "df_wide.to_csv(csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
